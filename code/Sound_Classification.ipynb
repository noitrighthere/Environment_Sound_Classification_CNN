{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Sound_Classification.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1b8LAsLcdte3"},"source":["# <center>Environmental Sound Classification with CNN</center>\n","---"]},{"cell_type":"code","metadata":{"id":"VCe9M7QY7o4B","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"stJu_LG7XiHZ","colab_type":"code","outputId":"2b20901f-c76c-42f3-cccc-202411b8782e","executionInfo":{"status":"ok","timestamp":1575898285247,"user_tz":-540,"elapsed":22394,"user":{"displayName":"‍노경환[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"12302221434260696963"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JHIWOGF9XhEe","colab_type":"text"},"source":["## Expand the cells width "]},{"cell_type":"code","metadata":{"id":"ivPX2ykAXhEg","colab_type":"code","outputId":"e565885d-135c-411a-ebb3-86ec7d686d71","executionInfo":{"status":"ok","timestamp":1575899732041,"user_tz":-540,"elapsed":656,"user":{"displayName":"‍노경환[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"12302221434260696963"}},"colab":{"base_uri":"https://localhost:8080/","height":17}},"source":["from IPython.core.display import display, HTML\n","display(HTML(\"<style>.container { width:100% !important; }</style>\"))"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<style>.container { width:100% !important; }</style>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"e_aZZRwpBMvM"},"source":["## Important libraries."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HR-S-faJdsAj","colab":{}},"source":["import re\n","import cv2\n","import os\n","import numpy as np\n","import pandas as pd\n","import librosa\n","import librosa.display\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from scipy.io import wavfile\n","from IPython.display import Audio\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.layers import Dense, Dropout, Flatten, Activation\n","\n","from __future__ import print_function\n","import tensorflow as tf\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QxGIhMLPd8Du"},"source":["## Read the training dataset(Audio files)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"X8U-M1BduDSB","colab":{}},"source":["audio_files = []\n","PATH = '/content/gdrive/My Drive/audio_6000'\n","\n","for file_name in tqdm(os.listdir(PATH)):\n","    try:\n","        audio, sampling_rate = librosa.load(os.path.join(PATH,file_name),res_type='kaiser_fast')\n","        \n","        # Since class name/number is hidden in file name of audio file, so we have to extract the class name/number by regular expression.\n","        exp = re.findall('\\d{1,2}.wav',file_name)\n","        audio_files.append([audio,int(float(exp[0][0:2]))])\n","    except Exception as e:\n","        pass"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sMtq5T9O3zlZ","colab_type":"code","outputId":"c86bec31-1752-4405-fb1f-811a521cd17d","executionInfo":{"status":"ok","timestamp":1575898547753,"user_tz":-540,"elapsed":602,"user":{"displayName":"‍노경환[학생](소프트웨어융합대학 컴퓨터공학과)","photoUrl":"","userId":"12302221434260696963"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":[""],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SrftNm48XhEq","colab_type":"text"},"source":["## Read and Explore the classes."]},{"cell_type":"code","metadata":{"id":"GwoxlT7UXhEr","colab_type":"code","colab":{}},"source":["#Read the Classes and Categories which i alerady saved in 'classes.csv' file\n","\n","df = pd.read_csv('/content/gdrive/My Drive/classes.csv',delimiter = ',') ## header of classes.\n","\n","categories = df.columns.tolist()\n","\n","classes =      list(df[categories[0]].values)\n","classes.extend(list(df[categories[1]].values))\n","classes.extend(list(df[categories[2]].values))\n","classes.extend(list(df[categories[3]].values))\n","classes.extend(list(df[categories[4]].values))\n","df"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pioEU9NsXhEu","colab_type":"text"},"source":["## Explore a random training example\n","<b>sampling_rate - </b> which keep the flow of number of element per second of audio files"]},{"cell_type":"code","metadata":{"id":"BtVXi7IgXhEv","colab_type":"code","colab":{}},"source":["number_of_training_example = len(audio_files)\n","\n","# One random index\n","random_index = np.random.randint(0,number_of_training_example)\n","\n","plt.figure(figsize=(20,5))\n","plt.subplot(121)\n","\n","audio, _class = audio_files[random_index][0],audio_files[random_index][1]\n","\n","# Convert audio into spectrogram\n","spectrogram = librosa.feature.melspectrogram(audio)\n","plt.title(\"Spectrogram\")\n","librosa.display.specshow(spectrogram, y_axis='mel', x_axis='time')\n","\n","# Convert into wave form \n","sampling_rate = int(len(audio)/5)\n","plt.subplot(122)\n","plt.title(\"Wave\")\n","librosa.display.waveplot(audio, sr=sampling_rate)\n","plt.ylabel('Amplitude')\n","plt.show()\n","\n","print('CLASS:',categories[int(_class/3)])\n","print('SUBCLASS:',classes[_class])\n","\n","#Audio\n","Audio(audio,rate = sampling_rate)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Abkf0mhuXhEy","colab_type":"code","colab":{}},"source":["audio_files= np.array(audio_files)\n","\n","X = list(audio_files[:,0])\n","\n","Y = audio_files[:,1]\n","\n","del audio_files"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uEIJii0dXhE0","colab_type":"text"},"source":["## Augmentation<br>\n","\n","<li><b> Data augmentation</b> is a technique to artificially create new training data from existing training data.</li>\n","<li> Since available dataset is not sufficient to train the model so i added the <b>white noise</b> to existing dataset.</li>\n","<li>Now we have 6000 training example.</li>"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tIzB8CEsNyi0","colab":{}},"source":["# It will take few seconds for augmentation.\n","size_of_audio_files = len(X[0])\n","\n","number_of_audio_files = len(Y)\n","\n","augmented_audio_files = []\n","\n","for i in range(number_of_audio_files): \n","    \n","    # Adding white noise\n","    X.append(X[i] + 0.005*np.random.randn(size_of_audio_files))\n","    \n","Y = np.r_[Y,Y]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6hAxo265Ogvx"},"source":["## Split  dataset into training and testing"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uHXxBw1VOgvz","colab":{}},"source":["train_x,test_x,train_y,test_y = train_test_split(X, Y, test_size = 0.1, random_state=5, shuffle = True)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_3fvTCJ_XhE6","colab_type":"text"},"source":["## Convert the input data into spectrogram to train the model"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"ggTNHWReXhE6","colab_type":"code","colab":{}},"source":["# It will take few seconds to covert audio into Spectrogram_files\n","x = train_x\n","train_x = []\n","length = len(train_y)\n","\n","for i in range(length):\n","    train_x.append(librosa.feature.melspectrogram(x[i], sampling_rate))\n","del x    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D1nXKTEdXhE9","colab_type":"code","colab":{}},"source":["# get the input diamention\n","SPEC_H, SPEC_W = train_x[0].shape\n","train_x = np.reshape(train_x,(length,SPEC_H, SPEC_W,1))\n","print(train_x.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fqdz6pDXXhFA","colab_type":"text"},"source":["## Create Compile and Train the model"]},{"cell_type":"code","metadata":{"id":"LNwjAjSwXhFB","colab_type":"code","colab":{}},"source":["# create the model\n","\n","model = Sequential()\n","\n","# add layers\n","model.add(Conv2D(64, kernel_size=3, activation=\"relu\", input_shape=(SPEC_H, SPEC_W, 1)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Conv2D(128, kernel_size=3, activation=\"relu\"))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Conv2D(256, kernel_size=3, activation=\"relu\"))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Conv2D(256, kernel_size=3, activation=\"relu\"))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Flatten())\n","model.add(Dense(256, activation = 'relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(128, activation = 'relu'))\n","model.add(Dense(15, activation=\"softmax\"))\n","\n","\n","# compile the model\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Training and Evaluation of the model\n","hist = model.fit(train_x, train_y, batch_size = 30 ,epochs=30,validation_split=0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LhbvmEYH9q3f","colab_type":"code","colab":{}},"source":["fig, loss_ax = plt.subplots()\n","\n","acc_ax = loss_ax.twinx()\n","\n","loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n","loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n","\n","acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n","acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n","\n","loss_ax.set_xlabel('epoch')\n","loss_ax.set_ylabel('loss')\n","acc_ax.set_ylabel('accuracy')\n","\n","loss_ax.legend(loc='upper left')\n","acc_ax.legend(loc='lower left')\n","\n","t_x = test_x\n","\n","test_x = []\n","length = len(test_y)\n","\n","for i in range(length):\n","    test_x.append(librosa.feature.melspectrogram(t_x[i], sampling_rate))\n","del t_x    \n","test_x = np.reshape(test_x,(length,SPEC_H, SPEC_W,1))\n","test_result = model.evaluate(test_x, test_y)\n","train_result = model.evaluate(train_x, train_y)\n","plt.show()\n","print(\"Change the model change dense layer(128) plus dropout layer(0.5)\")\n","print(\"epoch: 10, sampling rate =44100, sample label 15, total sample = 12000\")\n","print(\"Test Accuracy\",round(test_result[1],4))\n","print(\"Train Accuracy\",round(train_result[1],4))\n","\n","model.save(\"/content/gdrive/My Drive/train_label15_6000_final.h5\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HRbgXMhWiUtm","colab_type":"code","colab":{}},"source":["from keras.models import load_model\n","model2 = load_model('/content/gdrive/My Drive/train_label15_6000_final.h5')\n","t_x1 = test_x\n","\n","test_x = []\n","length = len(test_y)\n","\n","for i in range(length):\n","    \n","    test_x.append(librosa.feature.melspectrogram(t_x1[i], sampling_rate))\n","#del t_x1    \n","test_x = np.reshape(test_x,(length,SPEC_H, SPEC_W,1))\n","test_result = model2.evaluate(test_x, test_y)\n","train_result = model2.evaluate(train_x, train_y)\n","\n","\n","print(\"Test Accuracy\",round(test_result[1],4))\n","print(\"Train Accuracy\",round(train_result[1],4))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g3pRh5sRXhFJ","colab_type":"code","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]}]}